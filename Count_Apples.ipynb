{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e0e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\sucheta jhunjhunwala\\anaconda3\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\sucheta jhunjhunwala\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python     #Installing opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2cb4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2      #importing opencv\n",
    "import numpy as np   #import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d420a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('apples.mp4')    #Open the video file\n",
    "if cap.isOpened==False :                #Checks if video was opened correctly or not\n",
    "    print(\"Error opening video stream or file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18c500",
   "metadata": {},
   "source": [
    "# Method 1\n",
    "\n",
    "The target is to count the number of apples in a video. We shall first detect the apples in each frame by looking at the contours in each blurred frame. Then, count the number of apples as they go accross a vertical line drawn in the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d01fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgsub = cv2.createBackgroundSubtractorMOG2()  #creates an object to subtract the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c405cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_center(x,y,w,h):  #calculates the center of an apple\n",
    "    x1 = int(w/2)\n",
    "    y1 = int(h/2)\n",
    "    cx = x+x1\n",
    "    cy = y+y1\n",
    "    return cx,cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40efaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_position = 450   #height of the vertical line\n",
    "error = 6     #permissible error for the object identification\n",
    "counter = 0   #count of the apples\n",
    "min_width = 10   #min width of the rectangle\n",
    "min_height = 10   #min height of the rectangle\n",
    "detect = []  #list to store the center of an apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3701d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Apples: 25\n"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():   #When the video is opened\n",
    "    ret,frame = cap.read()    #returns each frame of the video\n",
    "    \n",
    "    if ret==True:     #Checks frame is being returned or not\n",
    "        img_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)   #changes the color space of image to grayscale\n",
    "        img_blur = cv2.GaussianBlur(img_gray,(3,3),5)    #blurs the image\n",
    "        img_bgsub = bgsub.apply(img_blur)     #removes the background from the image\n",
    "        img_dil = cv2.dilate(img_bgsub,np.ones((5,5)))  #widens the image\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))  #to get an elliptical kernel\n",
    "        img_close = cv2.morphologyEx(img_dil, cv2.MORPH_CLOSE,kernel)  #perfoms closing of the image using the kernel\n",
    "        img_close = cv2.morphologyEx(img_close, cv2.MORPH_CLOSE,kernel)\n",
    "        img_contour,h = cv2.findContours(img_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #finds all the contours in the image\n",
    "\n",
    "        cv2.line(frame, (15,line_position),(700,line_position), (255,0,0),2)  #adds a horizontal line to each frame\n",
    "        \n",
    "        for (i,j) in enumerate(img_contour):\n",
    "            (x,y,w,h)=cv2.boundingRect(j)  #draws rectangles around the binary images\n",
    "            max_size = (w>=min_width) and (h>=min_height)\n",
    "            if not max_size:\n",
    "                continue\n",
    "            if y<(line_position):    \n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),1)   #creates a rectangle\n",
    "                center = object_center(x,y,w,h)  #finds the center of each rectangle and hence each apple\n",
    "                detect.append(center)   \n",
    "            for (x,y) in detect:   #count the apples as they cross the line\n",
    "                if y>(line_position-error) and y<(line_position+error):\n",
    "                    counter+=1\n",
    "                detect.remove((x,y))\n",
    "                \n",
    "                \n",
    "        cv2.putText(frame,\"No. of Apples:\"+str(counter),(100,100),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1)  #displays the count\n",
    "                \n",
    "    \n",
    "        cv2.imshow('Apple Counter',frame)\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"Number of Apples: \"+str(counter))\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68dfbce",
   "metadata": {},
   "source": [
    "# Method 2\n",
    "\n",
    "My attempt was to look at frame in some particular intervals and then detect the number of apples in each such frame. The total number of apples in the video will be equal to the sum of the number of apples over each of these frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b6d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('apples.mp4')    #Open the video file\n",
    "if cap.isOpened==False :                #Checks if video was opened correctly or not\n",
    "    print(\"Error opening video stream or file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86f64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.33):\n",
    "    v = np.median(image)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))  #lower threshold\n",
    "    upper = int(min(255, (1.0 + sigma) * v))  #upper threshold\n",
    "    edged = cv2.Canny(image, lower, upper)  #finds the edges of each frame\n",
    "    return edged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be940580",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)  #get the number of frames in the video\n",
    "counter2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e21b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():    #When the video is opened\n",
    "    for i in range(int(frame_count)):\n",
    "        ret,frame = cap.read()  #returns each frame of the video\n",
    "        if i%100==0:\n",
    "            c_num=0\n",
    "\n",
    "            if ret==True:    #Checks frame is being returned or not\n",
    "                img_d = frame.copy()  #create a copy of each frame\n",
    "                img_blur = cv2.GaussianBlur(frame, (5,5), 0)   #blurs the image\n",
    "                img_ms = cv2.pyrMeanShiftFiltering(img_blur, 10, 90)  #filters the image\n",
    "\n",
    "                edge = auto_canny(img_ms)   #finds edges of each frame\n",
    "                cnts,_ = cv2.findContours(edge.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #Contours of the edged image\n",
    "                for i,c in enumerate(cnts):\n",
    "                    ((x, y), r) = cv2.minEnclosingCircle(c) #draw a circle around the objects\n",
    "                    if r>5:\n",
    "                        c_num+=1 #increase the count of apples in this frame\n",
    "                        cv2.circle(img_d, (int(x), int(y)), int(r), (0, 255, 0), 2)   #draw circles around the objects in the original video\n",
    "                    else:\n",
    "                        continue\n",
    "                counter2.append(c_num)  #number of apples in each frame\n",
    "                cv2.imshow('Original',img_d)\n",
    "                if cv2.waitKey(1)==13:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Number of Apples: \"+str(sum(counter2)))  #print the total number of apples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f44c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
